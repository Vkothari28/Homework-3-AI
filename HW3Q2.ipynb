{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6feb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv, copy, itertools, math, random\n",
    "from collections import Counter\n",
    "from scipy.special import expit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa5f2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataType(data):\n",
    "    for itr in range(len(data)):\n",
    "        val_u = data[itr]\n",
    "        if val_u == '?':\n",
    "            pass\n",
    "        else:\n",
    "            return val_u.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9b463f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in missing data - mode for stings and mean for numbers\n",
    "def bestGuessData(data):\n",
    "    if getDataType(data):  # if it's a string, find mode\n",
    "        data_count_dict = Counter(data)\n",
    "        return data_count_dict.most_common(1)[0][0]\n",
    "    else:  # if numbers, find average\n",
    "        data_wo_missing = [d for d in data if d != '?']\n",
    "        data_wo_missing = [float(d) for d in data_wo_missing]\n",
    "        return np.mean(data_wo_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a96c304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the best guess and replaces the missing data\n",
    "def replaceMissingData(filename):\n",
    "    dat = csv.reader(open(filename, 'r'), delimiter=';')\n",
    "\n",
    "    headers = ([h[0] for h in dat][0]).split(',')\n",
    "    columns = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        g = [r for r in reader]\n",
    "        f.close()\n",
    "        for j in range(len(headers)):\n",
    "            for i in range(len(g)):\n",
    "                columns.append([v for k, v in g[i].items() if k == headers[j]])\n",
    "    f.close()\n",
    "    columns = np.array(columns).reshape(len(headers), len(g))\n",
    "    bg = []\n",
    "    for i in range(len(headers)):\n",
    "        bg.append(bestGuessData(columns[i][:]))\n",
    "\n",
    "        columns[i][:] = [str(bg[i]) if x == '?' else x for x in columns[i][:]]\n",
    "    dict_str_x = ['normal', 'yes', 'present', 'good', 'ckd']\n",
    "    for i in range(len(columns)):\n",
    "        if columns[i][0].isalpha():\n",
    "            columns[i][:] = [1 if x in dict_str_x else 0 for x in columns[i][:]]\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    columns = columns.astype(np.float64)\n",
    "\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "43669c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    sig = 1.0 / (1.0 - ((np.exp(-x))))\n",
    "#     print((expit(-x)==1))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "87183ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypohesis\n",
    "def hyp_fn(w, x):\n",
    "    z = np.dot(w, x)\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a0dcb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing weights\n",
    "def compareWights(old, curr):\n",
    "    difference = curr - old\n",
    "    return np.sqrt(np.sum(np.square(difference)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae39051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease weights usin gradient descent and return new weights\n",
    "def gradientDescent(m, n, w, true_y, train_data, lambda_value, learning_rate, epsilon_tolerance):\n",
    "    flag_converged = 0\n",
    "    counter = 0\n",
    "    w_old = np.copy(w)\n",
    "\n",
    "    while True:\n",
    "        #counter += 1\n",
    "        hf = hyp_fn(w, train_data)\n",
    "        temp = np.dot(hf - true_y, train_data[1:, :].T)\n",
    "        w[0, 0] = w[0, 0] - (learning_rate / m) * np.sum(hf - true_y)  # +(lambda_value/m)*w[0,0]\n",
    "        for itr in range(n - 1):\n",
    "            w[:, 1:] = w[:, 1:] - (learning_rate / m) * np.sum(temp) + (lambda_value / m) * sum(w[:, 1:])\n",
    "        if compareWights(w_old, w) < epsilon_tolerance:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            w_old = np.copy(w)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef0b6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial weights aer chosen to be \"1.0\" fo simplicity\n",
    "def generateRandomInitialWeights(n):\n",
    "    weights = []\n",
    "    for i in range(n):\n",
    "        # weights.append(random.uniform(0,1))\n",
    "        weights.append(1.0)\n",
    "    weights = np.reshape(np.array(weights), (1, n))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "31078c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of data so data is comparable\n",
    "def normalizeData(d, n):\n",
    "    for itr in range(n):\n",
    "        mean = np.mean(d[itr])\n",
    "        std = np.std(d[itr])\n",
    "        d[itr] = (d[itr] - mean) / std\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "154eac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding weights needed to classify data\n",
    "def findWeights(train_data, m, n, lambda_value, epsilon_tolerance, learning_rate):\n",
    "    w_x = generateRandomInitialWeights(n)\n",
    "    true_y = np.reshape(train_data[-1], (1, m))\n",
    "    w_x = gradientDescent(m, n, w_x, true_y, train_data, lambda_value, learning_rate, epsilon_tolerance)\n",
    "    return w_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a50a2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation of f measure, returns f measure\n",
    "# compares true y with predicted y\n",
    "def evaluatePridictedWithTrue(predicted_class, true_class):\n",
    "    tp = np.sum([1.0 if (t == 1 and p == 1) else 0 for t, p in zip(predicted_class.T, true_class.T)])\n",
    "    ##print \"No. of true positives:\", tp# for t,p in zip(predicted_class.T, true_class.T):\n",
    "    fp = np.sum([1.0 if (p == 1 and t == 0) else 0 for t, p in zip(predicted_class.T, true_class.T)])\n",
    "    # print \"No. of false positives:\", fp\n",
    "    fn = np.sum([1.0 if (p == 0 and t == 1) else 0 for t, p in zip(predicted_class.T, true_class.T)])\n",
    "    # print \"No. of false negatives:\", fn\n",
    "    if (tp + fp) == 0 or (tp + fn) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        pre = tp / (tp + fp)\n",
    "        rec = tp / (tp + fn)\n",
    "        return 2 * pre * rec / (pre + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "35b4d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted y s assessed using f measure\n",
    "# and if the predicted y is > .5 the o/p is\n",
    "# classified as y = 1, and 0 otherwise\n",
    "def testing(x_test, y_test, wts_test):\n",
    "    y_predicted = hyp_fn(wts_test, x_test)\n",
    "    for i in range(80):\n",
    "        op = y_predicted[0, i]\n",
    "        if op > 0.5:\n",
    "            y_predicted[0, i] = 1\n",
    "        else:\n",
    "            y_predicted[0, i] = 0\n",
    "    # print \"Truth value compared to the predicted class and the ground truth is :\"\n",
    "    f_meas = evaluatePridictedWithTrue(y_predicted, y_test)\n",
    "    return f_meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbb80003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9612.46599658  8893.14332262  9777.41        8484.21\n",
      "   9018.63987494  9038.83437334  6872.515       9070.70994752\n",
      "  19324.405      22141.36599658 11516.43449953  8988.14487494\n",
      "   4826.00751258  9124.47099658 10359.2722377   8921.02556352\n",
      "  11960.751516    9027.92530957  7951.22        9016.39138545\n",
      "   8980.06081004  9424.25081004  8075.42        8968.14487494\n",
      "   8947.17854592  8924.13238752  8949.66081004  9219.91498262\n",
      "   8931.19587152  7491.87099658  9036.515      15157.31\n",
      "   8953.51688592  6861.10581084  6971.015       8851.23496144\n",
      "   6805.305       7589.81        8999.11437447 12365.46599658\n",
      "   9976.41        6223.28449953  8903.52530957  8871.85581004\n",
      "   4387.81        8944.77202837  9200.78130615  6385.16099658\n",
      "  13881.47693168  8871.36081004 10495.91       13085.215\n",
      "   6241.01        7758.91       12393.61        8877.05581004\n",
      "   8953.89587152  9558.015       6376.78449953 11158.51740793\n",
      "   8885.95581004 11233.315       7422.91743494 13499.77099658\n",
      "   8989.88130615  7311.815       7021.69193447 14311.915\n",
      "  10649.215       9019.05486945 11897.215       9706.71\n",
      "   8896.52076342 10364.82405862 10776.69944592  6110.80251258\n",
      "   8854.39518252 10378.4033759   8860.48036992  8906.60680662\n",
      "   9140.83937334  8883.99742532  9080.23538887 15415.01494752\n",
      "   6043.37099658  9112.52530957  8833.115      15780.915\n",
      "   5764.615       8959.93937334 16964.91       12827.30994752\n",
      "  13919.55357163  9025.215      10740.6028133   8980.34487494\n",
      "   9038.60146494  9853.81743494  8909.81988214  8929.88139094\n",
      "   9054.05081004  7075.75395094  9007.12530957  9124.95581004\n",
      "  11004.71        5008.151516    9003.25081004 15823.61\n",
      "   8983.98130615  8904.50587152  7081.08843152  8991.11437447\n",
      "   8846.03987494 15443.81        9136.12744     5186.78343152\n",
      "   8998.71180662  8401.925       9206.24987494 11557.51\n",
      "   9938.08449953 10758.27476068  6554.59193447  8616.31\n",
      "  10004.1840721   8959.95149862  8810.92530957  2666.48343152\n",
      "   7383.37843152  9009.97924742 10423.515      13284.12\n",
      "  13555.91       11528.42243494  9190.28449953  4807.0209351\n",
      "  12833.41        9111.70087152 10378.52743494  8951.19587152\n",
      "   9055.19587152 19575.725       8901.04987494  8918.05581004\n",
      "   6600.715       8807.31894704  8863.09732604 12747.77901962\n",
      "   8845.08344657  8119.61       17118.61        9735.6933759\n",
      "   8911.31180662  3259.961516    8960.09346507  9051.33437334\n",
      "  10216.61        4891.80551393 27053.02       11164.715\n",
      "   8515.025       8939.81437447  8920.11437447  9049.48224877\n",
      "   9038.43987494  8877.17037105  8949.53987494 11007.96599658\n",
      "   7635.34049611  7398.80262192 10544.715       8904.61180662\n",
      "   9520.815       8028.41        5458.07099658  8898.41057072\n",
      "   8866.86832582 11007.71        7431.47843152  8643.76599658\n",
      "   9278.27160752  9028.26081004  8923.68130615  9900.01\n",
      "   8850.26081004 12937.51        8082.115       7705.87099658\n",
      "   8919.38130615 16422.31       10033.12837004  9081.31437447\n",
      "   8956.94649862  8884.35581004  4615.70251258  6212.07343152\n",
      "   8882.81437447 10155.77843152  9215.91437447  8888.44487494\n",
      "   5586.07099658  4731.115      12136.91       11586.82\n",
      "  10691.715       7710.98449953  5667.015       8924.66581004\n",
      "  11014.91        6201.01       10882.725      10242.625\n",
      "   9578.625       6681.525       8758.725       9687.025\n",
      "  11197.125       9534.22        8851.42        4761.52\n",
      "   9899.22        6094.02        7678.42        9101.62\n",
      "   5495.72       10993.32        7289.52       10004.525\n",
      "   9006.16787543  7365.425       7662.425       9444.625\n",
      "   6097.525       8868.26081004  8848.14987494  5191.92\n",
      "   4994.759692    6790.525       9881.02        6276.225\n",
      "   8578.38449953  9634.725       5964.22       11349.81068858\n",
      "   7176.125       5755.52       10259.52        8867.65487494\n",
      "  11458.125       7554.52        8854.82        7506.525\n",
      "  10663.22        5165.7890721   8799.82       10076.48449953\n",
      "   6787.32        8176.925       9045.12       11537.82\n",
      "   9658.72        7652.325       8898.84987494  7178.37599658\n",
      "   6685.125       9579.12        4812.62        8381.12\n",
      "   7361.325       8577.32       11449.22        7987.125\n",
      "   6871.054692    8692.82        9901.925       8334.91568858\n",
      "   5453.4890721   8586.42        7499.925       8849.76081004\n",
      "  10896.82       10092.22        5004.48449953  8301.525\n",
      "   8875.86081004  7207.22        8753.82       11163.625\n",
      "   9076.5464367   8219.625       8878.37631164  7218.425\n",
      "  11010.461516    4768.42        6095.923176   11215.12\n",
      "   9638.07599658  7969.025       5229.62        7435.22\n",
      "   7145.825       7819.025       8163.02        5958.825\n",
      "   8576.12        8306.425       4789.08449953  7656.325\n",
      "   7755.02        9854.225      10055.425      10350.42\n",
      "   7472.22        6250.72        7227.825       6728.42\n",
      "   7852.525      11468.225       5656.32        6502.02      ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "data type <class 'numpy.object_'> not inexact",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-5b08889008e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mepsilon_tolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m155\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mwts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_tolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m################# Testing ######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-a9ef4256337e>\u001b[0m in \u001b[0;36mfindWeights\u001b[0;34m(train_data, m, n, lambda_value, epsilon_tolerance, learning_rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mw_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateRandomInitialWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrue_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mw_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_tolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-e23b70051689>\u001b[0m in \u001b[0;36mgradientDescent\u001b[0;34m(m, n, w, true_y, train_data, lambda_value, learning_rate, epsilon_tolerance)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#counter += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mhf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# +(lambda_value/m)*w[0,0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-4a789755ba63>\u001b[0m in \u001b[0;36mhyp_fn\u001b[0;34m(w, x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhyp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-9a2d4437af29>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data type %r not inexact\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finfo_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: data type <class 'numpy.object_'> not inexact"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # processing the data from files and relevant conversions\n",
    "    file = 'csv_result-chronic_kidney_disease_full (1).csv'\n",
    "    outfile = file\n",
    "    data_column_wise = replaceMissingData(outfile)  # outfile must be csv\n",
    "    n, no_samples = np.shape(data_column_wise)\n",
    "    m1 = int(.1 * no_samples)\n",
    "    m = int(.8 * no_samples)\n",
    "    train_x = np.copy(data_column_wise[:n - 1, m1:m + m1])  # data for training - 80%\n",
    "    train_y = np.copy(data_column_wise[n - 1:, m1:m + m1])\n",
    "    lambda_range = [-2.0, -1.8, -1.6, -1.4, -1.2, -1.0, -.8, -.6, -.4, -.2, 0, .2, .4, .6, .8, 1.0, 1.2, 1.4, 1.6, 1.8,\n",
    "                    2.0, 2.2, 2.4, 2.6, 2.8, 3.0, 3.2, 3.4, 3.6, 3.8, 4]\n",
    "#     lambda_range=np.arange(-2.0,4.2,.2)\n",
    "#     print(lambda_range)\n",
    "    f_m = []\n",
    "    for lambda_value in lambda_range:\n",
    "        # print \"lambda is =\", lambda_value\n",
    "        if lambda_value < -.6:\n",
    "            alpha = .1049  # 0.1049#0.07\n",
    "            epsilon_tolerance = 17000  # 17000# .5 for standardization\n",
    "        elif lambda_value > -.6 and lambda_value < -.2:\n",
    "            alpha = .001\n",
    "            epsilon_tolerance = 315\n",
    "        elif lambda_value >= -.2:  # and lambda_value<0 :\n",
    "            alpha = .001\n",
    "            epsilon_tolerance = 155\n",
    "\n",
    "        wts = findWeights(train_x, m, n - 1, lambda_value, epsilon_tolerance, alpha)\n",
    "\n",
    "        ################# Testing ######################\n",
    "\n",
    "        m_test = no_samples - m\n",
    "        test_x = np.copy(data_column_wise[:n - 1, :m1])  # data for testing - 20%\n",
    "        test_x = np.concatenate((test_x, np.copy(data_column_wise[:n - 1, m1 + m:])), axis=1)\n",
    "        y = np.copy(data_column_wise[n - 1:, :m1])  # true class\n",
    "        y = np.concatenate((y, np.copy(data_column_wise[n - 1:, m1 + m:])), axis=1)\n",
    "        temp_f_m = testing(test_x, y, wts)\n",
    "        # print \"f-meansure:\", temp_f_m\n",
    "        f_m.append(temp_f_m)\n",
    "    # print 70*'_'\n",
    "    # plotting f-measure vs lambda\n",
    "    plt.figure(\"f-measure vs lambda\")\n",
    "    plt.title(\"f-measure vs lambda\")\n",
    "    plt.plot(lambda_range, f_m, 'ro')\n",
    "    plt.xlabel(\"lambda = -2.0 to 4.0 in steps of 0.2\")\n",
    "    plt.ylabel(\"f-measure\")\n",
    "    plt.ylim((0, 1))\n",
    "    plt.xlim((-2, 4))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0f47ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###################################### Feature Normalization ######################################\n",
    "###################################################################################################\n",
    "import numpy as np\n",
    "import csv, copy, itertools, math, random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8be2a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fn identifies the missing data positions by finding the data type\n",
    "def getDataType(data):\n",
    "    for itr in range(len(data)):\n",
    "        val_u = data[itr]\n",
    "        if val_u == '?':\n",
    "            pass\n",
    "        else:\n",
    "            return val_u.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44fcd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in missing data - mode for stings and mean for numbers\n",
    "def bestGuessData(data):\n",
    "    if getDataType(data):  # if it's a string, find mode\n",
    "        data_count_dict = Counter(data)\n",
    "        return data_count_dict.most_common(1)[0][0]\n",
    "    else:  # if numbers, find average\n",
    "        data_wo_missing = [d for d in data if d != '?']\n",
    "        data_wo_missing = [float(d) for d in data_wo_missing]\n",
    "        return np.mean(data_wo_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ef485d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the best guess and replaces the missing data\n",
    "def replaceMissingData(filename):\n",
    "    dat = csv.reader(open(filename, 'r'), delimiter=';')\n",
    "\n",
    "    headers = ([h[0] for h in dat][0]).split(',')\n",
    "    columns = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        g = [r for r in reader]\n",
    "        f.close()\n",
    "        for j in range(len(headers)):\n",
    "            for i in range(len(g)):\n",
    "                columns.append([v for k, v in g[i].items() if k == headers[j]])\n",
    "    f.close()\n",
    "    columns = np.array(columns).reshape(len(headers), len(g))\n",
    "    bg = []\n",
    "    for i in range(len(headers)):\n",
    "        bg.append(bestGuessData(columns[i][:]))\n",
    "        dummy_list = columns[i][:]\n",
    "        columns[i][:] = [str(bg[i]) if x == '?' else x for x in columns[i][:]]\n",
    "    dict_str_x = ['normal', 'yes', 'present', 'good', 'ckd']\n",
    "    for i in range(len(columns)):\n",
    "        if columns[i][0].isalpha():\n",
    "            columns[i][:] = [1 if x in dict_str_x else 0 for x in columns[i][:]]\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    columns = columns.astype(np.float)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f59f4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9be64c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypohesis function for logit regression\n",
    "def hyp_fn(w, x):\n",
    "    z = np.dot(w, x)\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2fcc88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compaing old and new weights for convergence criteria\n",
    "def compareWights(old, curr):\n",
    "    difference = (curr - old)\n",
    "    difference = np.sqrt(np.sum(np.square(difference)))\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e064a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease weights usin gradient descent and return new weights\n",
    "def gradientDescent(m, n, w, true_y, train_data, lambda_value, learning_rate, epsilon_tolerance):\n",
    "    flag_converged = 0\n",
    "    counter = 0\n",
    "    w_old = np.copy(w)\n",
    "    # print \"counting iterations...\",\n",
    "    while True:\n",
    "        counter += 1\n",
    "        hf = hyp_fn(w, train_data)\n",
    "        temp = np.dot(hf - true_y, train_data[1:, :].T)\n",
    "        w[0, 0] = w[0, 0] - (learning_rate / m) * np.sum(hf - true_y)  # +(lambda_value/m)*w[0,0]\n",
    "        for itr in range(n - 1):\n",
    "            w[:, 1:] = w[:, 1:] - (learning_rate / m) * np.sum(temp) + (lambda_value / m) * sum(w[:, 1:])\n",
    "        if compareWights(w_old, w) < epsilon_tolerance:\n",
    "            # print \"\\nWeights have converged\",\n",
    "            flag_converged = 1\n",
    "            break\n",
    "        else:\n",
    "            w_old = np.copy(w)\n",
    "            pass\n",
    "    # print \".\",\n",
    "    # print \"\\n(converged in\", counter-1, \"iterations)\"\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94f7ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial weights aer chosen to be \"1.0\" fo simplicity\n",
    "def generateRandomInitialWeights(n):\n",
    "    weights = []\n",
    "    for i in range(n):\n",
    "        weights.append(1.0)\n",
    "    weights = np.reshape(np.array(weights), (1, n))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aaa662b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of data so data is comparable\n",
    "def normalizeData(d, n):\n",
    "    for itr in range(n):\n",
    "        mean = np.mean(d[itr])\n",
    "        std = np.std(d[itr])\n",
    "        d[itr] = (d[itr] - mean) / std\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa1e680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding weights needed to classify data\n",
    "def findWeights(train_data, m, n, lambda_value, epsilon_tolerance, learning_rate):\n",
    "    w_x = generateRandomInitialWeights(n)\n",
    "    true_y = np.reshape(train_data[-1], (1, m))\n",
    "    w_x = gradientDescent(m, n, w_x, true_y, train_data, lambda_value, learning_rate, epsilon_tolerance)\n",
    "    return w_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee582a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation of f measure, returns f measure\n",
    "# compares true y with predicted ydef evaluatePridictedWithTrue(predicted_class, true_class):\n",
    "def evaluatePridictedWithTrue(predicted_class, true_class):\n",
    "    tp = np.sum([1.0 if (t == 1 and p == 1) else 0 for t, p in zip(predicted_class.T, true_class.T)])\n",
    "    # print \"No. of true positives:\", tp# for t,p in zip(predicted_class.T, true_class.T):\n",
    "    fp = np.sum([1.0 if (p == 1 and t == 0) else 0 for t, p in zip(predicted_class.T, true_class.T)])\n",
    "    # print \"No. of false positives:\", fp\n",
    "    fn = np.sum([1.0 if (p == 0 and t == 1) else 0 for t, p in zip(predicted_class.T, true_class.T)])\n",
    "    # print \"No. of false negatives:\", fn\n",
    "    if (tp + fp) == 0:\n",
    "        return np.inf\n",
    "    else:\n",
    "        pre = tp / (tp + fp)\n",
    "        rec = tp / (tp + fn)\n",
    "        return 2 * pre * rec / (pre + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bfc88ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted y s assessed using f measure,\n",
    "# and if the predicted y is > .5 the o/p is\n",
    "# classified as y = 1, and 0 otherwisedef testing(x_test,y_test,wts_test):\n",
    "def testing(x_test, y_test, wts_test):\n",
    "    y_predicted = hyp_fn(wts_test, x_test)\n",
    "    for i in range(80):\n",
    "        op = y_predicted[0, i]\n",
    "        if op > 0.5:\n",
    "            y_predicted[0, i] = 1\n",
    "        else:\n",
    "            y_predicted[0, i] = 0\n",
    "    # print \"Truth value compared to the predicted class and the groud truth is :\"\n",
    "    f_meas = evaluatePridictedWithTrue(y_predicted, y_test)\n",
    "    return f_meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2dd14fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-ea25f1aab568>:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  columns = columns.astype(np.float)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b730b174fd59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_column_wise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# true class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_column_wise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtemp_f_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mf_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_f_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-424b9a1a9619>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(x_test, y_test, wts_test)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0my_predicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # processing the data from files and relevant conversions\n",
    "    file='csv_result-chronic_kidney_disease_full (1).csv'\n",
    "    outfile = file\n",
    "\n",
    "    data_column_wise = replaceMissingData(outfile)  # outfile must be csv\n",
    "    n, no_samples = np.shape(data_column_wise)\n",
    "    m1 = int(.1 * no_samples)\n",
    "    m = int(.8 * no_samples)\n",
    "    data_column_wise = normalizeData(data_column_wise, n - 1)  # uncomment this line for standardization\n",
    "    train_x = np.copy(data_column_wise[:n - 1, m1:m + m1])  # data for training - 80%\n",
    "    train_y = np.copy(data_column_wise[n - 1:, m1:m + m1])\n",
    "    lambda_range = np.arange(-2.0, 4.2, .2)\n",
    "    f_m = []\n",
    "    for lambda_value in lambda_range:\n",
    "        # print \"lambda is =\", lambda_value\n",
    "        if lambda_value < -0.4 and lambda_value < 0:\n",
    "            alpha = .002  # .01works for (1.0 or .9 ep)\n",
    "            epsilon_tolerance = .19  # 1.6for standardization/normalization\n",
    "        else:\n",
    "            alpha = .002\n",
    "            epsilon_tolerance = 21\n",
    "        \n",
    "        wts = findWeights(train_x, m, n - 1, lambda_value, epsilon_tolerance, alpha)\n",
    "        \n",
    "        test_x = np.copy(data_column_wise[:n - 1, :m1])  # data for testing - 20%\n",
    "        test_x = np.concatenate((test_x, np.copy(data_column_wise[:n - 1, m1 + m:])), axis=1)\n",
    "        y = np.copy(data_column_wise[n - 1:, :m1])  # true class\n",
    "        y = np.concatenate((y, np.copy(data_column_wise[n - 1:, m1 + m:])), axis=1)\n",
    "        temp_f_m = testing(test_x, y, wts)\n",
    "        f_m.append(temp_f_m)\n",
    "    \n",
    "    # plotting f-measure vs lambda\n",
    "    plt.figure(\"f-measure vs lambda\")\n",
    "    plt.title(\"f-measure vs lambda; alpha = .01\")\n",
    "    plt.plot(lambda_range, f_m, 'ro')\n",
    "    plt.xlabel(\"lambda = -2.0 to 4.0 in steps of 0.2\")\n",
    "    plt.ylabel(\"f-measure\")\n",
    "    plt.ylim((0, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40e7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
